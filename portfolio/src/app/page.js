"use client";
import React, { useRef, useState, useEffect } from "react";
import { Canvas, useFrame } from "@react-three/fiber";
import { OrbitControls, Stars, useGLTF } from "@react-three/drei";
import Model from "../../Components/Model.js";
import { Lipsync } from "wawa-lipsync";
import SkillSection from "../../Components/Skills.js";
import RotatingStars from "../../Components/RotatingStar.js";
import GameDesk from "../../Components/GameDesk.js";
import Navbar from "../../Components/Navbar.js";
import Projects from "../../Components/ProjectSection.js";
import gsap from "gsap";
import Contact from "../../Components/Contact.js"
const lipsyncManager = new Lipsync();

export default function CharacterCanvas() {
Â  const audioRef = useRef(null);
Â  const [viseme, setViseme] = useState("");
Â  const [isListening, setIsListening] = useState(false);
Â  const rafId = useRef(null);
Â  const headingRef = useRef();

Â  useEffect(() => {
Â  Â  gsap.fromTo(
Â  Â  Â  headingRef.current.children,
Â  Â  Â  { x: "20px", opacity: 0 },
Â  Â  Â  { x: "0px", opacity: 1, duration: 1, stagger: 0.2, ease: "power2.out",delay:2 }
Â  Â  );
Â  }, []);

Â  const analyzeAudio = () => {
Â  Â  lipsyncManager.processAudio();
Â  Â  setViseme(lipsyncManager.viseme);
Â  Â  rafId.current = requestAnimationFrame(analyzeAudio);
Â  };

Â  const stop = () => {
Â  Â  if (rafId.current) {
Â  Â  Â  cancelAnimationFrame(rafId.current);
Â  Â  Â  rafId.current = null;
Â  Â  }
Â  };

Â  const handleSTT = () => {
Â  Â  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
Â  Â  if (!SpeechRecognition) return alert("SpeechRecognition not supported");

Â  Â  const recognition = new SpeechRecognition();
Â  Â  recognition.lang = "en-US";
Â  Â  recognition.interimResults = false;
Â  Â  recognition.maxAlternatives = 1;

Â  Â  recognition.onstart = () => setIsListening(true);
Â  Â  recognition.onend = () => setIsListening(false);

Â  Â  recognition.onresult = async (e) => {
Â  Â  Â  const text = e.results[0][0].transcript;
Â  Â  Â  console.log("User said:", text);

Â  Â  Â  const res1 = await fetch("https://portfolio-backend-node.vercel.app/chat", {
Â  Â  Â  Â  method: "POST",
Â  Â  Â  Â  headers: { "Content-Type": "application/json" },
Â  Â  Â  Â  body: JSON.stringify({ prompt: text }),
Â  Â  Â  });

Â  Â  Â  const responseText = await res1.text();

Â  Â  Â  const res2 = await fetch("https://portfolio-backend-node-5dkf.vercel.app/ask", {
Â  Â  Â  Â  method: "POST",
Â  Â  Â  Â  headers: { "Content-Type": "application/json" },
Â  Â  Â  Â  body: JSON.stringify({ prompt: responseText }),
Â  Â  Â  });

Â  Â  Â  const blob = await res2.blob();
Â  Â  Â  const audioUrl = URL.createObjectURL(blob);

Â  Â  Â  const audio = audioRef.current;
Â  Â  Â  audio.src = audioUrl;
Â  Â  Â  lipsyncManager.connectAudio(audio);
Â  Â  Â  audio.play();
Â  Â  Â  analyzeAudio();
Â  Â  };

Â  Â  recognition.onerror = (err) => {
Â  Â  Â  console.error("STT Error:", err);
Â  Â  Â  setIsListening(false);
Â  Â  };

Â  Â  recognition.start();
Â  };

Â  return (
Â  Â  <div style={{ fontFamily: "sans-serif", backgroundColor: "#000", color: "#fff", minHeight: "100vh" }}>
Â  Â  Â  <Navbar />

Â  Â  Â  <section id="hero" style={{ position: "relative", height: "70vh", display: "flex", flexDirection: "column", alignItems: "center", justifyContent: "center", overflow: "hidden" }}>
Â  Â  Â  Â  <Canvas style={{ position: "absolute", top: 0, left: 0, width: "100%", height: "100%" }}>
Â  Â  Â  Â  Â  <RotatingStars />
Â  Â  Â  Â  Â  <GameDesk />
Â  Â  Â  Â  Â  <ambientLight intensity={2} />
Â  Â  Â  Â  Â  <spotLight position={[-5, 5, 5]} angle={0.4} intensity={3} color="#6A0DAD" castShadow />
Â  Â  Â  Â  Â  <spotLight position={[5, 5, 5]} angle={0.4} intensity={3} color="#00FFFF" castShadow />
Â  Â  Â  Â  </Canvas>
Â  Â  Â  Â  <div style={{ position: "relative", zIndex: 1, textAlign: "center", color: "#fff", padding: "2rem" }} ref={headingRef}>
Â  Â  Â  Â  Â  <h1 style={{ fontSize: "3rem", marginBottom: "1rem" }}>Hi, I'm Suraj Chawhan</h1>
Â  Â  Â  Â  Â  <p style={{ fontSize: "1.25rem", maxWidth: "600px", margin: "0 auto" }}>
Â  Â  Â  Â  Â  Â  Iâ€™m a passionate developer creating innovative AI and interactive 3D experiences.
Â  Â  Â  Â  Â  </p>
Â  Â  Â  Â  </div>
Â  Â  Â  </section>

Â  Â  Â  <SkillSection />
Â  Â  Â  <Projects />

Â  Â  Â  <section id="ai" style={{ padding: "40px 20px", textAlign: "center" }}>
Â  Â  Â  Â  <h2 style={{ fontSize: "2.5rem", color: "white", marginBottom: "10px" }}>Talk to my Ai Avatar</h2>
Â  Â  Â  Â  <Canvas style={{ height: "60vh", borderRadius: "12px" }} camera={{ position: [0, 2, 5] }}>
Â  Â  Â  Â  Â  <ambientLight intensity={4} />
Â  Â  Â  Â  Â  <spotLight angle={0.4} intensity={60} color="purple" position={[-2, 5, 5]} />
Â  Â  Â  Â  Â  <spotLight angle={0.4} intensity={60} color="blue" position={[2, 5, 5]} />
Â  Â  Â  Â  Â  <directionalLight position={[2, 4, 2]} intensity={5} />
Â  Â  Â  Â  Â  <RotatingStars />
Â  Â  Â  Â  Â  <Model viseme={viseme} />
Â  Â  Â  Â  </Canvas>
Â  Â  Â  Â  <button
Â  Â  Â  Â  Â  onClick={handleSTT}
Â  Â  Â  Â  Â  style={{
Â  Â  Â  Â  Â  Â  marginTop: "25px",
Â  Â  Â  Â  Â  Â  padding: "12px 24px",
Â  Â  Â  Â  Â  Â  fontSize: "1rem",
Â  Â  Â  Â  Â  Â  fontWeight: "bold",
Â  Â  Â  Â  Â  Â  backgroundColor: "#6A0DAD",
Â  Â  Â  Â  Â  Â  color: "white",
Â  Â  Â  Â  Â  Â  border: "none",
Â  Â  Â  Â  Â  Â  borderRadius: "8px",
Â  Â  Â  Â  Â  Â  cursor: "pointer",
Â  Â  Â  Â  Â  Â  transition: "background-color 0.3s ease",
Â  Â  Â  Â  Â  }}
Â  Â  Â  Â  >
Â  Â  Â  Â  Â  ðŸŽ¤ {isListening ? "Listening..." : "Speak to AI"}
Â  Â  Â  Â  </button>
Â  Â  Â  Â  <audio ref={audioRef} crossOrigin="anonymous" onEnded={stop} />
Â  Â  Â  </section>

Â  <Contact/>
Â  Â  </div>
Â  );
}
